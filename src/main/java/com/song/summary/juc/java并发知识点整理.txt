1.进程与线程：
    进程：进程是程序的一次执行，是系统进行资源分配和调度的独立单位。
    线程：线程是比进程更小的能独立运行的基本单位（基本的cpu执行单元），是轻量级的进程，也是进程的一个实体。一个进程可以包含多个线程，线程基本不拥有系统资源，只拥有一些运行时必不可少的资源，
         比如程序计数器、寄存器和栈等。线程与同属一个进程的其他线程共享进程的全部资源，线程的上下文切换可以减少程序并发执行时的时间和空间开销，使得操作系统具有更好的并发性。
2.JMM内存模型（java内存模型）：
    回答JMM模型，要把握两个点：
        1.私有数据区域与共享数据区域的交互，或者线程与线程之间的交互。
        2.是一个抽象的模型，屏蔽掉了不同操作系统处理之间的差异。
    a.什么是JMM内存模型？：JMM内存模型描述的是一组规则，通过这组规则控制程序中各个变量在共享数据区域和私有数据区域的访问方式，JMM是围绕原子性、有序性、可见性展开的。模型中主要为线程、工作内存、主内存之间的交互。
        JMM内存模型中规定所有变量都存储在主内存，主内存是共享内存区域，所有线程都可以访问，但线程对变量的操作(读取赋值等)必须在工作内存中进行，首先要将变量从主内存拷贝到自己的工作内存空间中，
        然后对变量进行操作，操作完成后再将变量写回主内存，不能直接操作主内存中的变量，工作内存中存储着主内存中的变量副本拷贝，前面说过，工作内存是每个线程的私有数据区域，因此不同的线程间无法访问对方的工作内存，
        线程间的通信(传值)必须通过主内存来完成。
    b.JMM与硬件内存架构的关系：JMM模型跟CPU缓存模型结构类似，是基于CPU缓存模型建立起来的，JMM模型是标准化的，屏蔽掉了底层不同计算机的区别。对于硬件内存来说只有寄存器、缓存内存、主内存的概念，
        并没有工作内存(线程私有数据区域)和主内存(堆内存)之分，因为JMM只是一种抽象的概念，是一组规则，并不实际存在，不管是工作内存的数据还是主内存的数据，对于计算机硬件来说都会存储在计算机主内存中，
        当然也有可能存储到CPU缓存或者寄存器中，因此总体上来说，Java内存模型和计算机硬件内存架构是一个相互交叉的关系，是一种抽象概念划分与真实物理硬件的交叉。
    c.Java内存模型内存交互操作：关于主内存与工作内存之间的具体交互协议，即一个变量如何从主内存拷贝到工作内存、如何从工作内存同步到主内存之间的实现细节，Java内存模型定义了以下八种操作来完成。
        1.数据同步八大原子操作：
            lock(锁定)：作用于主内存的变量，把一个变量标记为一条线程独占状态。
            unlock(解锁)：作用于主内存的变量，把一个处于锁定状态的变量释放出来，释放后的变量才可以被其他线程锁定。
            read(读取)：作用于主内存的变量，把一个变量值从主内存传输到线程的工作内存中，以便随后的load动作使用。
            load(载入)：作用于工作内存的变量，它把read操作从主内存中得到的变量值放入工作内存的变量副本中。
            use(使用)：作用于工作内存的变量，把工作内存中的一个变量值传递给执行引擎。
            assign(赋值)：作用于工作内存的变量，它把一个从执行引擎接收到的值赋给工作内存的变量。
            store(存储)：作用于工作内存的变量，把工作内存中的一个变量的值传送到主内存中，以便随后的write的操作。
            write(写入)：作用于工作内存的变量，它把store操作从工作内存中的一个变量的值传送到主内存的变量中。
        把一个变量从主内存中复制到工作内存中，就需要按顺序地执行read和load操作，如果把变量从工作内存中同步到主内存中，就需要按顺序地执行store和write操作。
        但Java内存模型只要求上述8大操作(原子操作)必须按顺序执行，而没有保证必须是连续执行。
        补充：
            Java线程内存模型（JMM）是建立在先行发生（happens-before）的内存模型之上的，并进行了增强。
            happens-before内存模型：先行发生模型。如果有两个操作A和B存在A Happens-Before B，那么操作A对变量的修改对操作B来说是可见的。这个先行并不是代码执行时间上的先后关系，而是保证执行结果是顺序的。
                                  即在JMM中，如果一个操作执行的结果需要对另一个操作可见，那么这两个操作之间必须存在happens-before关系。
            happens-before定义：1. 如果一个操作happens-before另一个操作，那么第一个操作的执行结果将对第二个操作可见，而且第一个操作的执行顺序排在第二个操作之前。
                               2. 两个操作之间存在happens-before关系，并不意味着一定要按照happens-before原则制定的顺序来执行。如果重排序之后的执行结果与按照happens-before关系来执行的结果一致，
                                  那么这种重排序并不非法。
            happens-before原则：
                1.程序次序规则：一个线程内，按照代码顺序，书写在前面的操作先行发生于书写在后面的操作；
                2.锁定规则：一个unLock操作先行发生于后面对同一个锁的lock操作；
                3.volatile变量规则：对一个变量的写操作先行发生于后面对这个变量的读操作；
                4.传递规则：如果操作A先行发生于操作B，而操作B又先行发生于操作C，则可以得出操作A先行发生于操作C；
                5.线程启动规则：Thread对象的start()方法先行发生于此线程的每个一个动作；
                6.线程中断规则：对线程interrupt()方法的调用先行发生于被中断线程的代码检测到中断事件的发生；
                7.线程终结规则：线程中所有的操作都先行发生于线程的终止检测，我们可以通过Thread.join()方法结束、Thread.isAlive()的返回值手段检测到线程已经终止执行；
                8.对象终结规则：一个对象的初始化完成先行发生于他的finalize()方法的开始。
        2.同步规则：
            1.不允许一个线程无原因地（没有发生过任何assign操作）把数据从工作内存同步回主内存中
            2.一个新的变量只能在主内存中诞生，不允许在工作内存中直接使用一个未被初始化（load或者assign）的变量。即就是对一个变量实施use和store操作之前，必须先自行assign和load操作。
            3.一个变量在同一时刻只允许一条线程对其进行lock操作，但lock操作可以被同一线程重复执行多次，多次执行lock后，只有执行相同次数的unlock操作，变量才会被解锁。lock和unlock必须成对出现。
            4.如果对一个变量执行lock操作，将会清空工作内存中此变量的值，在执行引擎使用这个变量之前需要重新执行load或assign操作初始化变量的值。
            5.如果一个变量事先没有被lock操作锁定，则不允许对它执行unlock操作；也不允许去unlock一个被其他线程锁定的变量。
            6.对一个变量执行unlock操作之前，必须先把此变量同步到主内存中（执行store和write操作）。
        3.交互举例：图片及代码见附件
            详解：对于ThreadA，会经过read、load操作将flag读入工作内存（本地内存），然后use操作写入cpu core1（寄存器保存）对于ThreadB，也会有上面的步骤。但最后是写入cpu core2（因为cpu core1一直在被占用），
                 然后给flag赋值为false，再经过assign操作写回工作内存，注意，此时不会立马执行store、write操作，写回主内存，而是在某一时刻进行，此时，ThreadA继续读取flag，是从工作内存中加载的，
                 不是从主内存中加载的。
                 load函数中doSomething(0);传入的值，从0到4：
                     0，什么也不做，while(flag)一直在进行，threadA的工作内存缓存一直有效，因此一直未从主内存中读取，一直是true。
                     1，sleep，会让出CPU时间片，线程上下文切换（保存现场、恢复现场），因此会从主内存中重新读取flag，读到了false则跳出循环。
                        注意：与sleep的时间没有关系，即使sleep 0ms，也会让出CPU时间片。
                     2，使用System.out.println输出，println方法实现内部有synchronized(this)操作，synchronized会保证可见性，因此会从主内存中读取flag。读到了false则跳出循环。
                     3，等待10微秒，太短了，缓存未失效，因此一直未从主内存中读取，一直是true。
                     4，等到20微秒，缓存失效了，因此会从主内存中读取，读到了false则跳出循环。
                 给flag变量加上volatile关键词后 private volatile boolean flag = true; 上述0-4，执行都会跳出循环。
            上面例子表示了volatile关键字的含义之一：保证变量对所有线程的可见性。
3.并发的三大特性：
    a.原子性（Atomicity）：即一个操作或者多个操作，要么全部执行并且不被打断，要么就都不执行。
    b.可见性（Visibility）：当一个线程修改了共享变量的值，其他线程会马上知道这个修改。当其他线程要读取这个变量的时候，最终会去内存中读取，而不是从缓存中读取。
    c.有序性（Ordering）：虚拟机在进行代码编译时，对于那些改变顺序之后不会对最终结果造成影响的代码，虚拟机不一定会按照我们写的代码的顺序来执行，有可能将他们重排序。实际上，对于有些代码进行重排序之后，
                        虽然对变量的值没有造成影响，但有可能会出现线程安全问题。
4.volatile底层实现原理：
    a.volatile内存语义：
        volatile是Java虚拟机提供的轻量级的同步机制。
        volatile语义有如下两个作用：
        1.可见性：保证被volatile修饰的共享变量对所有线程总数可见的，也就是当一个线程修改了一个被volatile修饰共享变量的值，新值总是可以被其他线程立即得知。
        2.有序性：禁止指令重排序优化。
    b.volatile缓存可见性实现原理：
        1.JMM内存交互层面：volatile修饰的变量的read、load、use操作和assign、store、write必须是连续的，即修改后必须立即同步回主内存，使用时必须从主内存刷新，由此保证volatile变量的可见性。
        2.底层实现：通过汇编lock前缀指令，它会锁定变量缓存行区域并写回主内存，这个操作称为“缓存锁定”，缓存一致性机制会阻止同时修改被两个以上处理器缓存的内存区域数据。
                  一个处理器的缓存回写到内存会导致其他处理器的缓存无效。
        汇编代码查看：-XX:+UnlockDiagnosticVMOptions -XX:+PrintAssembly -Xcomp
        补充：
            1.Lock作用：
                a. 确保后续指令执行的原子性。在Pentium及之前的处理器中，带有lock前缀的指令在执行期间会锁住总线，使得其它处理器暂时无法通过总线访问内存，很显然，这个开销很大。在新的处理器中，
                   Intel使用缓存锁定来保证指令执行的原子性，缓存锁定将大大降低lock前缀指令的执行开销。
                b. 禁止该指令与前面和后面的读写指令重排序。
                c. 把写缓冲区的所有数据刷新到主内存中。
            2.缓存一致性协议（MESI）：
                MESI协议是当前最主流的缓存一致性协议，在MESI协议中，每个缓存行有4个状态，可用2个bit表示，它们分别是：Modified（修改）、Exclusive（独占，互斥）、Share（共享）、Invalid（无效）。详见图片
                这里的I、S和M状态已经有了对应的概念：失效/未载入、干净以及脏的缓存段。所以这里新的知识点只有E状态，代表独占式访问，这个状态解决了"在我们开始修改某块内存之前，我们需要告诉其它处理器"这一问题：
                只有当缓存行处于E或者M状态时，处理器才能去写它，也就是说只有在这两种状态下，处理器是独占这个缓存行的。当处理器想写某个缓存行时，如果它没有独占权，它必须先发送一条"我要独占权"的请求给总线，
                这会通知其它处理器把它们拥有的同一缓存段的拷贝失效（如果有）。只有在获得独占权后，处理器才能开始修改数据----并且此时这个处理器知道，这个缓存行只有一份拷贝，在我自己的缓存里，所以不会有任何冲突。
                反之，如果有其它处理器想读取这个缓存行（通过总线嗅探机制能立马知道），独占或已修改的缓存行必须先回到"共享"状态。如果是已修改的缓存行，那么还要先把内容回写到内存中。
                举例：
                    问题：线程1修改主存里某个变量的值，线程2要读取这个变量的值，在MESI协议下是怎么操作的？
                    答：线程1改完值并将变量所在的缓存行状态变为Modified后，会通过总线嗅探机制通知线程2将自己本地存储该变量的缓存行状态变为Invalid，线程2再读取自己本地缓存行中该变量的值时，需要从主内存读取，
                       同时线程1需要将自己本地缓存行状态变为Shared，且要将更改后的变量值回写到主内存中。
    c.volatile禁止指令重排序优化：
        1.指令重排序：
            java语言规范规定JVM线程内部维持顺序化语义。即只要程序的最终结果与它顺序化情况的结果相等，那么指令的执行顺序可以与代码顺序不一致，此过程叫指令的重排序。
            指令重排序的意义：JVM能根据处理器特性（CPU多级缓存系统、多核处理器等）适当的对机器指令进行重排序，使机器指令能更符合CPU的执行特性，最大限度的发挥机器性能。
            在编译器与CPU处理器中都能执行指令重排优化操作。详见图片
            补充：as-if-serial
                as-if-serial语义的意思是：不管怎么重排序（编译器和处理器为了提高并行度），（单线程）程序的执行结果不能被改变。编译器、runtime和处理器都必须遵守as-if-serial语义。
                为了遵守as-if-serial语义，编译器和处理器不会对存在数据依赖关系的操作做重排序，因为这种重排序会改变执行结果。但是，如果操作之间不存在数据依赖关系，这些操作就可能被编译器和处理器重排序。
        2.volatile重排序规则：详见图片
            1.第二个操作是volatile写，不管第一个操作是什么都不会重排序。
            2.第一个操作是volatile读，不管第二个操作是什么都不会重排序。
            3.第一个操作是volatile写，第二个操作是volatile读，也不会发生重排序。
            X86处理器不会对读-读、读-写和写-写操作做重排序, 会省略掉这3种操作类型对应的内存屏障。仅会对写-读操作做重排序，所以volatile写-读操作只需要在volatile写后插入StoreLoad屏障。
        3.内存屏障（memory barrier）：
            硬件层提供了一系列的内存屏障 memory barrier/memory fence(Intel的提法)来提供一致性的能力。
            拿X86平台来说，有几种主要的内存屏障：
                1. lfence，是一种Load Barrier读屏障。
                2. sfence，是一种Store Barrier写屏障。
                3. mfence，是一种全能型的屏障，具备lfence和sfence的能力。
                4. Lock前缀，Lock不是一种内存屏障，但是它能完成类似内存屏障的功能。Lock会对CPU总线和高速缓存加锁，可以理解为CPU指令级的一种锁。它后面可以跟ADD, ADC, AND, BTC, BTR, BTS, CMPXCHG,
                   CMPXCH8B, DEC, INC, NEG, NOT, OR, SBB, SUB, XOR, XADD, and XCHG等指令。
            内存屏障有两个能力：
                1. 阻止屏障两边的指令重排序（保证特定操作的执行顺序）。
                2. 刷新处理器缓存/冲刷处理器缓存（保证某些变量的内存可见性）。
            对Load Barrier来说，在读指令前插入读屏障，可以让高速缓存中的数据失效，重新从主内存加载数据。
            对Store Barrier来说，在写指令之后插入写屏障，能让写入缓存的最新数据写回到主内存。
            Lock前缀实现了类似的能力，它先对总线和缓存加锁，然后执行后面的指令，最后释放锁后会把高速缓存中的数据刷新回主内存。在Lock锁住总线的时候，其他CPU的读写请求都会被阻塞，直到锁释放。
            不同硬件实现内存屏障的方式不同，Java内存模型屏蔽了这种底层硬件平台的差异，由JVM来为不同的平台生成相应的机器码。
            为了实现volatile的禁止指令重排序，编译器在生成字节码时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。
            JMM内存屏障插入策略：详见图片
                1.在每个volatile写操作的前面插入一个StoreStore屏障。
                2.在每个volatile写操作的后面插入一个StoreLoad屏障。
                3.在每个volatile读操作的后面插入一个LoadLoad屏障。
                4.在每个volatile读操作的后面插入一个LoadStore屏障。
5.CAS（比较并交换-乐观锁机制-锁自旋）：
    CAS可以看做是乐观锁的一种实现方式，Java原子类中的递增操作就通过CAS自旋实现的。
    CAS全称Compare And Swap (比较与交换)，是一种无锁算法。在不使用锁(没有线程被阻塞)的情况下实现多线程之间的变量同步。
    LOCK_IF_MP(%4) "cmpxchgl %1,(%3)" lock  cmpxchgl：汇编指令（CAS操作的汇编指令）。
    unsafe.compareAndSwapInt(this, valueOffset, expect, update);
        上面的方法，有几个重要的参数：
        this，需要改变的对象。
        valueOffset，value变量的内存偏移地址。
        expect，期望更新的值。
        update，要更新的最新值。
        如果原子变量中的value值等于expect，则使用update值更新该值并返回true，否则返回false。
    缺点：
    只能保证对一个变量的原子性操作
    长时间自旋会给CPU带来压力
    ABA问题：
        CAS算法实现一个重要前提需要取出内存中某时刻的数据，而在下一时刻比较并替换，那么在这个时间差类会导致数据的变化。比如说一个线程one从内存位置V中取出A，这时候另一个线程two也从内存中取出A，并且
        two进行了一些操作变成了B，然后two又将V位置的数据变成A，这时候线程one进行CAS操作发现内存中仍然是A，然后one操作成功。尽管线程one的CAS操作成功，但是不代表这个过程就是没有问题的。
        部分乐观锁的实现是通过版本号（version）的方式来解决ABA问题，乐观锁每次在执行数据的修改操作时，都会带上一个版本号，一旦版本号和数据的版本号一致就可以执行修改操作并对版本号执行+1操作，
        否则就执行失败。因为每次操作的版本号都会随之增加，所以不会出现ABA问题，因为版本号只会增加不会减少。
6.java线程的生命周期：
    a.六种状态：NEW（初始化状态）、RUNNABLE（可运行/运行状态）、BLOCKED（阻塞状态）、WAITING（无时限等待）、TIMED_WAITING（有时限等待）、TERMINATED（终止状态）。
        在操作系统层面，java线程中的BLOCKED、WAITING、TIMED_WAITING是一种状态，即前面我们提到的休眠状态。也就是说只要java线程处于这三种状态之一，那么这个线程就永远没有CPU的使用权。
        其中，BLOCKED、WAITING、TIMED_WAITING可以理解为线程导致休眠状态的三种原因。
    b.线程状态转换：
        RUNNABLE与BLOCKED的状态转换：
            只有一种场景会触发这种转换，就是线程等待synchronized的隐式锁。synchronized修饰的方法、代码块同一时刻只允许一个线程执行，其他线程只能等待，这种情况下，
            等待的线程就会从RUNNABLE转换到BLOCKED状态。而当等待的线程获得synchronized隐式锁时，就又会从BLOCKED转换到RUNNABLE状态。
        RUNNABLE与WAITING的状态转换：
            总体来说，有三种场景会触发这种转换：
                1.获得synchronized隐式锁的线程调用了无参数的Object.wait()方法。
                2.调用无参数的Thread.join()方法。其中的join()是一种线程同步方法，例如有一个线程对象thread A，当调用A.join()的时候，执行这条语句的线程会等待thread A执行完，而等待中的这个线程，
                  其状态会从RUNNABLE转换到WAITING。当线程thread A执行完，原来等待它的线程又会从WAITING状态转换到RUNNABLE。
                3.调用LockSupport.park()方法。其中的LockSupport对象，也许你有点陌生，其实java并发包中的锁，都是基于它实现的。调用LockSupport.park()方法，当前线程会阻塞，
                  线程的状态会从RUNNABLE转换到WAITING。调用LockSupport.unpark(Thread thread)可唤醒目标线程，目标线程的状态又会从WAITING状态转换到RUNNABLE。
        RUNNABLE与TIMED_WAITING的状态转换：
            有五种场景会触发这种转换：
                1.调用带超时参数的Thread.sleep(long millis)方法；
                2.获得synchronized隐式锁的线程，调用带超时参数的Object.wait(long timeout)方法；
                3.调用带超时参数的Thread.join(long millis)方法；
                4.调用带超时参数的LockSupport.parkNanos(Object blocker, long deadline)方法；
                5.调用带超时参数的LockSupport.parkUntil(long deadline)方法。
                  这里你会发现TIMED_WAITING和WAITING状态的区别，仅仅是触发条件多了超时参数。
        从NEW到RUNNABLE状态：
            java刚创建出来的Thread对象就是NEW状态，NEW状态的线程，不会被操作系统调度，因此不会执行。java线程要执行，就必须转换到RUNNABLE状态。从NEW状态转换到RUNNABLE状态很简单，只要调用线程对象的start()方法就可以了。
        从RUNNABLE到TERMINATED状态：
            线程执行完run()方法后，会自动转换到TERMINATED状态，当然如果执行run()方法的时候异常抛出，也会导致线程终止。有时需要强制中断run()方法的执行，可以调用Thread类里面的stop()方法，不过已经标记为@Deprecated，
            所以不建议使用，可以改为调用interrupt()方法。
7.java锁体系：详见图片，https://www.cnblogs.com/jyroy/p/11365935.html（特别好的一篇文章）
    java中的锁主要为：内置锁synchronized（一种独占锁），juc包下的锁。
    锁有哪些：乐观锁、悲观锁、自旋锁、适应性自旋锁、无锁、偏向锁、轻量级锁、重量级锁、公平锁、非公平锁、可重入锁、不可重入锁、独享锁、共享锁。
8.synchronized和ReentrantLock的区别：
    a.两者的共同点：
        1.都是用来协调多线程对共享对象、变量的访问。
        2.都是可重入锁，同一线程可以多次获得同一个锁。
        3.都保证了可见性和互斥性。
    b.两者的不同点：
        1.ReentrantLock显示的获得、释放锁，synchronized隐式获得释放锁。
        2.ReentrantLock可响应中断、可轮回，synchronized是不可以响应中断的，为处理锁的不可用性提供了更高的灵活性。
        3.ReentrantLock是API级别的，synchronized是JVM级别的。
        4.ReentrantLock可以实现公平锁。
        5.ReentrantLock通过Condition可以绑定多个条件。
        6.底层实现不一样，synchronized是同步阻塞，使用的是悲观并发策略，lock是同步非阻塞，采用的是乐观并发策略。
        7.Lock是一个接口，而synchronized是Java中的关键字，synchronized是内置的语言实现。
        8.synchronized在发生异常时，会自动释放线程占有的锁，因此不会导致死锁现象发生；而Lock在发生异常时，如果没有主动通过unLock()去释放锁，则很可能造成死锁现象，因此使用Lock时需要在finally块中释放锁。
        9.Lock可以让等待锁的线程响应中断，而synchronized却不行，使用synchronized时，等待的线程会一直等待下去，不能够响应中断。
        10.通过Lock可以知道有没有成功获取锁，而synchronized却无法办到。
        11.Lock可以提高多个线程进行读操作的效率，既就是实现读写锁等。
9.synchronized底层实现原理：
    a.synchronized加锁方式：
        同步实例方法，锁是当前实例对象。
        同步类方法（static修饰），锁是当前类对象。
        同步代码块，锁是括号里面的对象。
    b.synchronized原理：
        synchronized是基于JVM内置锁实现，通过内部对象monitor(监视器锁)实现，基于进入与退出monitor对象实现方法与代码块同步，监视器锁的实现依赖底层操作系统的Mutex lock（互斥锁）。
        synchronized关键字修饰同步代码块时，会在编译成字节码后被翻译成monitorenter和monitorexit两条指令分别插在同步块逻辑代码的起始位置与结束位置。而修饰同步方法时，会在⽅法中的access_flags中设置ACC_SYNCHRONIZED标志。
        无论修饰同步代码块还是同步方法，执行线程都要先获取monitor，获取成功之后才能执行代码块或方法体，方法执行完后再释放monitor。在方法执行期间，其他任何线程都无法再获得同一个monitor对象。
        两种同步方式本质上没有区别，只是方法的同步是一种隐式的方式来实现，无需通过字节码来完成。两个指令的执行是JVM通过调用操作系统的互斥原语mutex来实现，被阻塞的线程会被挂起、等待重新调度，
        会导致线程在“用户态和内核态”两个状态之间来回切换，对性能有较大影响。所以从jdk1.6开始，对synchronized的实现机制进⾏了较⼤优化。
    c.monitor（监视器锁）：
        任何一个对象都有一个monitor与之关联，当且一个monitor被持有后，它将处于锁定状态。
        1.代码块同步：
            分别插在同步块逻辑代码的起始位置与结束位置插入monitorenter和monitorexit指令（字节码层面）。
            monitorenter：每个对象都是一个监视器锁（monitor）。当monitor被占用时就会处于锁定状态，线程执行monitorenter指令时尝试获取monitor的所有权，
                          过程如下：a. 如果monitor的进入数为0，则该线程进入monitor，然后将进入数设置为1，该线程即为monitor的所有者；
                                  b. 如果线程已经占有该monitor，只是重新进入，则进入monitor的进入数加1；
                                  c. 如果其他线程已经占用了monitor，则该线程进入阻塞状态，直到monitor的进入数为0，再重新尝试获取monitor的所有权；
            monitorexit：执行monitorexit的线程必须是objectref所对应的monitor的所有者。指令执行时，monitor的进入数减1，如果减1后进入数为0，那线程退出monitor，不再是这个monitor的所有者。
                         其他被这个monitor阻塞的线程可以尝试去获取这个monitor的所有权。
            monitorexit指令出现了两次，第1次为同步正常退出释放锁，第2次为发生异常退出释放锁；
        2.方法同步：
            当方法调用时，调用指令将会检查方法的ACC_SYNCHRONIZED访问标志是否被设置，如果设置了，执行线程将先获取monitor，获取成功之后才能执行方法体，方法执行完后再释放monitor。
        其实wait/notify等方法也依赖于monitor对象，这就是为什么只有在同步的块或者方法中才能调用wait/notify等方法，否则会抛出java.lang.IllegalMonitorStateException的异常的原因。
        补充：
            monitor可以把它理解为一个同步工具，也可以描述为一种同步机制，它通常被描述为一个对象。与其它对象一样，所有的java对象都可以是monitor，因为在Java的设计中 ，每一个java对象都携带了一把看不见的锁，
            它叫做内部锁或者monitor锁。也就是通常说synchronized的对象锁，MarkWord锁标识位为10，其中指针指向的是monitor对象的起始地址。在Java虚拟机（HotSpot）中，monitor是由ObjectMonitor实现的，
            其主要数据结构如下（位于HotSpot虚拟机源码ObjectMonitor.hpp文件，C++实现的）：
                ObjectMonitor(){
                    _header =NULL;
                    _count =0;// 记录个数
                    _waiters =0;
                    _recursions =0;
                    _object =NULL;
                    _owner =NULL;
                    _WaitSet =NULL;// 处于wait状态的线程，会被加入到_WaitSet
                    _WaitSetLock =0;
                    _Responsible =NULL;
                    _succ =NULL;
                    _cxq =NULL;
                    FreeNext =NULL;
                    _EntryList =NULL;// 处于等待锁block状态的线程，会被加入到该列表
                    _SpinFreq =0;
                    _SpinClock =0;
                    OwnerIsThread =0;
                }
            ObjectMonitor中有两个队列，_WaitSet和_EntryList，用来保存ObjectWaiter对象列表（每个等待锁的线程都会被封装成ObjectWaiter对象），_owner指向持有ObjectMonitor对象的线程，
            当多个线程同时访问一段同步代码时：
                1. 首先会进入_EntryList集合，当线程获取到对象的monitor后，进入_Owner区域并把monitor中的owner变量设置为当前线程，同时monitor中的计数器count加1；
                2. 若线程调用wait()方法，将释放当前持有的monitor，owner变量恢复为null，count自减1，同时该线程进入WaitSet集合中等待被唤醒；
                3. 若当前线程执行完毕，也将释放monitor（锁）并复位count的值，以便其他线程进入获取monitor(锁)；
            同时，monitor对象存在于每个Java对象的对象头Mark Word中（存储的指针的指向），synchronized锁便是通过这种方式获取锁的，也是为什么Java中任意对象可以作为锁的原因，
            同时notify/notifyAll/wait等方法会使用到monitor锁对象，所以必须在同步代码块中使用。监视器monitor有两种同步方式：互斥与协作。多线程环境下线程之间如果需要共享数据，
            需要解决互斥访问数据的问题，监视器可以确保监视器上的数据在同一时刻只会有一个线程在访问。
        synchronized加锁加在对象上，锁状态是被记录在每个对象的对象头（Mark Word）中。
    d.对象的内存布局以及Mark Word布局：详见图片。
    e.synchronized锁升级过程（基于jdk1.6后的优化）：
        锁的状态总共有四种，无锁状态、偏向锁、轻量级锁和重量级锁。随着锁的竞争，锁可以从偏向锁升级到轻量级锁，再升级的重量级锁，但是锁的升级是单向的，也就是说只能从低到高升级，不会出现锁的降级。
        jdk1.6中默认是开启偏向锁和轻量级锁的，可以通过-XX:-UseBiasedLocking来禁用偏向锁。
        锁的升级全过程详见图片。
10.AQS&Lock：
    a.AQS：
        java并发编程的核心在于java.util.concurrent包。而juc当中大多数同步器实现都是围绕着共同的基础行为，比如等待队列、条件队列、独占获取、共享获取等，而这个行为的抽象就是基于AbstractQueuedSynchronizer，
        简称AQS。AQS定义了一套多线程访问共享资源的同步器框架，是一个依赖状态（state）的同步器。
        AQS具备特性：
            阻塞等待队列
            共享/独占
            公平/⾮公平
            可重⼊
            允许中断
        除了Lock外，Java.concurrent.util当中同步器的实现如Latch，Barrier，BlockingQueue等，都是基于AQS框架实现：
            一般通过定义内部类Sync继承AQS。
            将同步器所有调用都映射到Sync对应的方法。
        AQS内部维护属性volatile int state (32位)
            state表示资源的可用状态。
        State三种访问方式：
            getState()、setState()、compareAndSetState()。
        AQS定义两种资源共享方式：
            Exclusive-独占，只有一个线程能执行，如ReentrantLock。
            Share-共享，多个线程可以同时执行，如Semaphore/CountDownLatchAQS定义两种队列同步等待队列条件等待队列。
        AQS定义两种队列：
            同步等待队列（CLH）：
                CLH同步队列是一个先进先出的队列，实现为双向链表，AQS依赖它来完成同步状态的管理：
                    当前线程如果获取同步状态失败时，AQS则会将当前线程已经等待状态等信息构造成一个节点（Node）并将其加入到CLH同步队列，同时会阻塞当前线程。
                    当同步状态释放时，会把首节点唤醒，使其再次尝试获取同步状态。
            条件等待队列（Condition）：
                Condition将Object监视器方法（wait、notify和notifyAll）分解成截然不同的对象，以便通过将这些对象与任意Lock实现组合使用，为每个对象提供多个等待set（wait-set）。
                其中，Lock替代了synchronized方法和语句的使用，Condition替代了Object监视器方法的使用。
        不同的自定义同步器争用共享资源的方式也不同。自定义同步器在实现时只需要实现共享资源state的获取与释放方式即可，至于具体线程等待队列的维护（如获取资源失败入队/唤醒出队等），AQS已经在顶层实现好了。
        自定义同步器实现时主要实现以下几种方法：
            isHeldExclusively()：该线程是否正在独占资源。只有用到condition才需要去实现它。
            tryAcquire(int)：独占方式。尝试获取资源，成功则返回true，失败则返回false。
            tryRelease(int)：独占方式。尝试释放资源，成功则返回true，失败则返回false。
            tryAcquireShared(int)：共享方式。尝试获取资源。负数表示失败；0表示成功，但没有剩余可用资源；正数表示成功，且有剩余资源。
            tryReleaseShared(int)：共享方式。尝试释放资源，如果释放后允许唤醒后续等待结点返回true，否则返回false。
    b.ReentrantLock：
        ReentrantLock是一种基于AQS框架的应用实现，是JDK中的一种线程并发访问的同步手段，它的功能类似于synchronized是一种互斥锁，可以保证线程安全。而且它具有比synchronized更多的特性，
        比如它支持手动加锁与解锁，支持公平、非公平锁。
            //使用ReentrantLock进行同步
            ReentrantLock lock = newReentrantLock(false);//false为非公平锁，true为公平锁
            lock.lock()//加锁
            lock.unlock()//解锁
        ReentrantLock如何实现synchronized不具备的公平与非公平性呢？
            在ReentrantLock内部定义了一个Sync的内部类，该类继承AbstractQueuedSynchronized，对该抽象类的部分方法做了实现；
            并且还定义了两个子类：
                1.FairSync 公平锁的实现。
                2.NonfairSync 非公平锁的实现这两个类都继承自Sync，也就是间接继承了AbstractQueuedSynchronized，所以这一个ReentrantLock同时具备公平与非公平特性。
                上面主要涉及的设计模式：模板模式-子类根据需要做具体业务实现。
        AQS独占锁底层实现：
            state初始的时候为0，在多线程条件下，线程要执行临界区的代码，必须首先获取state，某个线程获取成功之后，通过CAS操作将state加1，其他线程再获取的话由于共享资源已被占用，所以会到FIFO等待队列去等待，
            等占有state的线程执行完临界区的代码释放资源(state减1)后，会唤醒FIFO队列中的下一个等待线程（head中的下一个结点）去获取state。
            state由于是多线程共享变量，所以必须定义成volatile，以保证state的可见性, 同时虽然volatile能保证可见性，但不能保证原子性，所以AQS提供了对state的原子操作方法（通过CAS操作），保证了线程安全。
            另外AQS中实现的FIFO队列（CLH 队列）其实是双向链表实现的，由head, tail节点表示，head结点代表当前占用的线程，其他节点由于暂时获取不到锁所以依次排队等待锁释放。
            两篇比较好的相关文章：
                https://mp.weixin.qq.com/s/iNz6sTen2CSOdLE0j7qu9A
                https://mp.weixin.qq.com/s/trsjgUFRrz40Simq2VKxTA
    c.CountDownLatch&Semaphore&CyclicBarrier：
        相关文章：
            https://mp.weixin.qq.com/s/TDw7GnzDw5FK3RWwkIzzZA
            https://www.yuque.com/books/share/9f4576fb-9aa9-4965-abf3-b3a36433faa6/cburl0
11.java线程池：
    线程池做的工作主要是控制运行的线程的数量，处理过程中将任务放入队列，然后在线程创建后启动这些任务，如果线程数量超过了最大数量超出数量的线程排队等候，等其它线程执行完毕，再从队列中取出任务来执行。
    a.线程池优势：
        重用存在的线程，减少线程创建，消亡的开销，提高性能。
        提高响应速度。当任务到达时，任务可以不需要的等到线程创建就能立即执行。
        提高线程的可管理性。线程是稀缺资源，如果无限制的创建，不仅会消耗系统资源，还会降低系统的稳定性，使用线程池可以进行统一的分配，调优和监控。
    b.线程池的实现：
        java中的线程池是通过Executor框架实现的，该框架中用到了Executor，Executors，ExecutorService，ThreadPoolExecutor ，Callable和Future、FutureTask这几个类。
        严格意义上讲Executor并不是一个线程池，而只是一个执行线程的工具。真正的线程池接口是ExecutorService，其中定义了线程池的具体行为：
            1.execute（Runnable command）：履行Ruannable类型的任务,
            2.submit（task）：可用来提交Callable或Runnable任务，并返回代表此任务的Future对象
            3.shutdown（）：在完成已提交的任务后封闭办事，不再接管新任务,
            4.shutdownNow（）：停止所有正在履行的任务并封闭办事。
            5.isTerminated（）：测试是否所有任务都履行完毕了。
            6.isShutdown（）：测试是否该ExecutorService已被关闭。
        几种线程池：
            1.ThreadPoolExecutor（默认线程池）：
                ThreadPoolExecutor的构造方法如下：
                    public ThreadPoolExecutor(int corePoolSize,int maximumPoolSize, long keepAliveTime,
                        TimeUnit unit, BlockingQueue<Runnable> workQueue) {
                        this(corePoolSize, maximumPoolSize, keepAliveTime, unit, workQueue,
                        Executors.defaultThreadFactory(), defaultHandler);
                    }
                1. corePoolSize：指定了线程池中的线程数量。
                2. maximumPoolSize：指定了线程池中的最大线程数量。
                3. keepAliveTime：当前线程池数量超过corePoolSize时，多余的空闲线程的存活时间，即多次时间内会被销毁。
                4. unit：keepAliveTime的单位。
                5. workQueue：任务队列，被提交但尚未被执行的任务。
                    在JDK中提供了如下阻塞队列：
                    a.ArrayBlockingQueue：基于数组结构的有界阻塞队列，按FIFO排序任务；
                    b.LinkedBlockingQueue：基于链表结构的阻塞队列，按FIFO排序任务，吞吐量通常要高于ArrayBlockingQueue；
                    c.SynchronousQueue：一个不存储元素的阻塞队列，每个插入操作必须等到另一个线程调用移除操作，否则插入操作一直处于阻塞状态，吞吐量通常要高于LinkedBlockingQueue；
                    d.priorityBlockingQueue：具有优先级的无界阻塞队列；
                6. threadFactory：线程工厂，用于创建线程，一般用默认的即可。
                7. handler：拒绝策略，线程池中的线程已经用完了，无法继续为新任务服务，同时，等待队列也已经排满了，再也塞不下新任务了。这时候我们就需要拒绝策略机制合理的处理这个问题。
                    JDK内置的拒绝策略如下：
                        1. AbortPolicy ：直接抛出异常，阻止系统正常运行，默认策略。
                        2. CallerRunsPolicy ：只要线程池未关闭，该策略直接在调用者线程中，运行当前被丢弃的任务。显然这样做不会真的丢弃任务，但是，任务提交线程的性能极有可能会急剧下降。
                        3. DiscardOldestPolicy ：丢弃最老的一个请求，也就是即将被执行的一个任务，并尝试再次提交当前任务。
                        4. DiscardPolicy ：该策略默默地丢弃无法处理的任务，不予任何处理。如果允许任务丢失，这是最好的一种方案。
                    以上内置拒绝策略均实现了RejectedExecutionHandler接口，若以上策略仍无法满足实际需要，完全可以自己扩展RejectedExecutionHandler接口。
            2.newCachedThreadPool：
                创建一个可根据需要创建新线程的线程池，但是在以前构造的线程可用时将重用它们。对于执行很多短期异步任务的程序而言，这些线程池通常可提高程序性能。调用execute将重用以前构造
                的线程（如果线程可用）。如果现有线程没有可用的，则创建一个新线程并添加到池中。终止并从缓存中移除那些已有60秒钟未被使用的线程。因此，长时间保持空闲的线程池不会使用任何资源。
            3.newFixedThreadPool：
                创建一个可重用固定线程数的线程池，以共享的无界队列方式来运行这些线程。在任意点，在大多数nThreads线程会处于处理任务的活动状态。如果在所有线程处于活动状态时提交附加任务，
                则在有可用线程之前，附加任务将在队列中等待。如果在关闭前的执行期间由于失败而导致任何线程终止，那么一个新线程将代替它执行后续的任务（如果需要）。在某个线程被显式地关闭之
                前，池中的线程将一直存在。
            4.newScheduledThreadPool：
                创建一个线程池，它可安排在给定延迟后运行命令或者定期地执行。
            5.newSingleThreadExecutor：
                Executors.newSingleThreadExecutor()返回一个线程池（这个线程池只有一个线程）,这个线程池可以在线程死后（或发生异常时）重新启动一个线程来替代原来的线程继续执行下去。
    c.线程池工作原理：
        1.线程池刚创建时，里面没有一个线程。任务队列是作为参数传进来的。不过，就算队列里面有任务，线程池也不会马上执行它们。
        2.当调用execute()方法添加一个任务时，线程池会做如下判断：
            a)如果正在运行的线程数量小于corePoolSize，那么马上创建线程运行这个任务；
            b)如果正在运行的线程数量大于或等于corePoolSize，那么将这个任务放入队列；
            c)如果这时候队列满了，而且正在运行的线程数量小于maximumPoolSize，那么还是要创建非核心线程立刻运行这个任务；
            d)如果队列满了，而且正在运行的线程数量大于或等于maximumPoolSize，那么线程池会抛出异常RejectExecutionException。
        3.当一个线程完成任务时，它会从队列中取下一个任务来执行。
        4.当一个线程无事可做，超过一定的时间（keepAliveTime）时，线程池会判断，如果当前运行的线程数大于corePoolSize，那么这个线程就被停掉。所以线程池的所有任务完成后，它
          最终会收缩到corePoolSize的大小。
12.ThreadLocal：https://mp.weixin.qq.com/s/LzkZXPtLW2dqPoz3kh3pBQ

