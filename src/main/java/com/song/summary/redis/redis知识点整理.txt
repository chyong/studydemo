1.redis的单线程和高性能：
    a.redis是单线程吗？
        redis的单线程主要是指redis的网络IO和键值对读写是由一个线程来完成的，这也是redis对外提供键值存储服务的主要流程。但redis的其他功能，比如持久化、异步删除、集群数据同步等，其实是由额外的线程执行的。
    b.redis单线程为什么还能这么快？
        因为它所有的数据都在内存中，所有的运算都是内存级别的运算，而且单线程避免了多线程的上下文切换性能损耗问题。正因为redis是单线程，所以要小心使用redis指令，对于那些耗时的指令(比如keys)，一定要谨慎使用，
        一不小心就可能会导致redis卡顿。
    c.redis单线程如何处理那么多的并发客户端连接？
        redis的IO多路复用：redis利用epoll来实现IO多路复用，将连接信息和事件放到队列中，依次放到文件事件分派器，事件分派器将事件分发给事件处理器。
2.redis五种基本数据类型：
    String、Hash、List、Set、SortedSet（即zset）。
        扩展：
            a.String：
                redis中的字符串是一种简单动态字符串（simple dynamic string），它的结构为：
                    struct sdshdr{
                     int len; //记录buf数组中已使用字节的数量，等于SDS所保存字符串的长度
                     int free; //记录buf数组中未使用字节的数量
                     char buf[]; //字节数组，用于保存字符串
                    }
                SDS与C字符串的区别：
                   1.常数复杂度获取字符串长度(O(1))：
                        C字符串要获取自身的长度必须遍历整个字符串，时间复杂度为O(n)，而SDS保存了自身的长度len，获取只需要O(1)的时间复杂度。
                   2.杜绝缓冲区溢出：
                        C字符串在进行字符串拼接时如果没有提前分配足够的内存空间，会导致拼接后的结果覆盖原先字符串的值（缓冲区溢出），而SDS进行字符串拼接的时候会先检查内存空间是否足够，如果不够
                        则先扩展内存空间，然后进行字符串拼接，有效避免了缓冲区溢出。
                   3.减少修改字符串时带来的内存重分配次数：
                        redis是个高速缓存数据库，如果我们需要对字符串进行频繁的拼接和截断操作，写代码时又忘记了重新分配内存，就可能造成缓冲区溢出，以及内存泄露。而且内存分配算法很耗时，
                        对于一个高速缓存数据库来说，这样的开销也是我们应该要避免的。redis为了避免C字符串这样的缺陷，就分别采用了两种解决方案，空间预分配和惰性空间释放：
                            空间预分配：
                                当我们对SDS进行空间扩展操作的时候，redis不仅会为SDS分配修改所必须要的空间，还会为SDS分配额外的未使用空间（free）。额外分配的未使用空间数量由以下公式决定：
                                    1.SDS的长度（也即是len属性的值）小于1MB，那么redis会分配和len属性同样大小的未使用空间，这时SDS len属性的值将和free属性的值相同，比如：
                                      13byte + 13byte + 1byte = 27byte，其中1byte用于保存空字符。
                                    2.SDS的长度（也即是len属性的值）大于等于1MB，那么redis会分配1MB的未使用空间。比如：30 MB + 1 MB + 1 byte
                                通过空间预分配策略，redis可以减少连续执行字符串增长操作所需的内存重分配次数。即SDS拼接时，如果free空间够，直接用free空间，不需要再额外分配内存。
                            惰性空间释放：
                                当我们执行完一个字符串缩减的操作，redis并不会马上回收已分配的内存空间，而是使用free属性将这些字节的数量记录起来，并等待将来使用，即利用free空间来存放后面要
                                拼接的字符串，通过惰性空间释放策略，SDS避免了缩短字符串时所需的内存重分配操作，并为将来可能有的增长操作提供了优化。当free空间一直未使用到的时候，redis还是会
                                回收这部分内存空间的，避免了内存的浪费。
                   4.二进制安全：
                        C字符串中的字符必须符合某种编码（比如ASCII），并且除了字符串的末尾之外，字符串里面不能包含空字符，否则最先被程序读入的空字符将被误认为是字符串结尾，且空字符后面的字符串
                        无法被识别，这些限制使得C字符串只能保存文本数据，而不能保存像图片、音频、视频、压缩文件这样的二进制数据。但SDS可以做到这些，因为SDS使用len属性的值而不是空字符来判断字
                        符串是否结束，读取字符串时直接从buf读取len数量的字符串即可。
            b.Hash（字典）：
                redis中的字典相当于Java中的HashMap，内部实现也差不多类似，都是通过"数组 + 链表"的链地址法来解决部分哈希冲突，同时这样的结构也吸收了两种不同数据结构的优点。table属性是一个数组，
                数组中的每个元素都是一个指向dictEntry结构的指针，而每个dictEntry结构保存着一个键值对。实际上字典结构的内部包含两个hashtable，通常情况下只有一个hashtable是有值的，但是在字典扩容缩容时，
                需要分配新的hashtable，然后进行渐进式搬迁。
                渐进式rehash：
                    大字典的扩容是比较耗时间的，需要重新申请新的数组，然后将旧字典所有链表中的元素重新挂接到新的数组下面，这是一个O(n)级别的操作，作为单线程的redis很难承受这样耗时的过程，
                    所以redis使用渐进式rehash逐步搬迁（ht[0]->ht[1]）：
                        1.为ht[1]分配空间，让字典同时持有ht[0]和ht[1]两个哈希表。
                        2.在字典中维持一个索引计数器变量rehashidx，并将它的值设置为0，表示rehash工作正式开始。
                        3.在rehash进行期间，每次对字典执行添加、删除、查找或者更新操作时，程序除了执行指定的操作以外，还会顺带将ht[0]哈希表在rehashidx索引上的所有键值对rehash到ht[1]，当rehash工作完成之后，
                          程序将rehashidx属性的值增一。
                        4.随着字典操作的不断执行，最终在某个时间点上，ht[0]的所有键值对都会被rehash至ht[1]，这时程序将rehashidx属性的值设为-1，表示rehash操作已完成。
                    在渐进式rehash进行期间，字典的删除（delete）、查找（find）、更新（update）等操作会在两个哈希表上进行：比如说，要在字典里面查找一个键的话，程序会先在ht[0]里面进行查找，如果没找到的话，
                    就会继续到ht[1]里面进行查找，诸如此类。另外，在渐进式rehash执行期间，新添加到字典的键值对一律会被保存到ht[1]里面，而ht[0]则不再进行任何添加操作：这一措施保证了ht[0]包含的键值对数量会只减不增，
                    并随着rehash操作的执行而最终变成空表。
                扩缩容的条件：
                    正常情况下，当hash表中元素的个数等于第一维数组的长度时，就会开始扩容，扩容的新数组是原数组大小的2倍。不过如果redis正在做bgsave(持久化命令)，为了减少内存池的过多分离，redis尽量不去扩容，
                    但是如果hash表非常满了，达到了第一维数组长度的5倍了，这个时候就会强制扩容。当hash表因为元素逐渐被删除变得越来越稀疏时，redis会对hash表进行缩容来减少hash表的第一维数组空间占用。
                    所用的条件是元素个数低于数组长度的10%，缩容不会考虑redis是否在做bgsave。
            c.List（列表）：
                redis的列表相当于Java语言中的LinkedList，注意它是链表而不是数组。这意味着list的插入和删除操作非常快，时间复杂度为 O(1)，但是索引定位很慢，时间复杂度为O(n)，所以一般用作队列。
                每个链表节点使用一个listNode结构来表示：
                    typedef struct listNode {
                        // 前置节点
                        struct listNode *prev;
                        // 后置节点
                        struct listNode *next;
                        // 节点的值
                        void *value;
                    } listNode;
                多个listNode可以通过prev和next指针组成双端链表，虽然仅仅使用多个listNode结构就可以组成链表，但使用list来持有链表的话，操作起来会更方便：
                    typedef struct list {
                        // 表头节点
                        listNode *head;
                        // 表尾节点
                        listNode *tail;
                        // 链表所包含的节点数量
                        unsigned long len;
                        // 节点值复制函数
                        void *(*dup)(void *ptr);
                        // 节点值释放函数
                        void (*free)(void *ptr);
                        // 节点值对比函数
                        int (*match)(void *ptr, void *key);
                    } list;
                list结构为链表提供了表头指针head、表尾指针tail，以及链表长度计数器len，而dup、free和match成员则是用于实现多态链表所需的类型特定函数：
                    dup 函数用于复制链表节点所保存的值；
                    free 函数用于释放链表节点所保存的值；
                    match 函数则用于对比链表节点所保存的值和另一个输入值是否相等。
                redis的链表实现的特性可以总结如下：
                    双端：链表节点带有prev和next指针，获取某个节点的前置节点和后置节点的复杂度都是O(1)。
                    无环：表头节点的prev指针和表尾节点的next指针都指向NULL，对链表的访问以NULL为终点。
                    带表头指针和表尾指针：通过list结构的head指针和tail指针，程序获取链表的表头节点和表尾节点的复杂度为O(1)。
                    带链表长度计数器：程序使用list结构的len属性来对list持有的链表节点进行计数，程序获取链表中节点数量的复杂度为O(1)。
                    多态：链表节点使用void*指针来保存节点值，并且可以通过list结构的dup、free、match三个属性为节点值设置类型特定函数，所以链表可以用于保存各种不同类型的值。
            d.Set（集合）：
                redis的集合相当于Java语言中的HashSet，它内部的键值对是无序、唯一的。它的内部实现相当于一个特殊的字典（hash），字典中所有的value都是一个值NULL。
            e.SortedSet（即zset，有序集合）：
                redis最具特色的一个数据结构，它类似于Java中SortedSet和HashMap的结合体，一方面它是一个set，保证了内部value的唯一性，另一方面它可以为每个value赋予一个score值，用来代表排序的权重。
                它的内部实现用的是一种叫做「跳跃表」的数据结构：
                    跳跃表（skiplist）是一种有序数据结构，它通过在每个节点中维持多个指向其他节点的指针，从而达到快速访问节点的目的。跳跃表支持平均O(\log N)最坏O(N)复杂度的节点查找，
                    还可以通过顺序性操作来批量处理节点。在大部分情况下，跳跃表的效率可以和平衡树相媲美，并且因为跳跃表的实现比平衡树要来得更为简单，所以有不少程序都使用跳跃表来代替平衡树。
                    redis使用跳跃表作为有序集合键的底层实现之一：如果一个有序集合包含的元素数量比较多，又或者有序集合中元素的成员（member）是比较长的字符串时，redis就会使用跳跃表来作为有序集合键的底层实现。
                    跳跃表的实现：
                        http://redisbook.com/preview/skiplist/datastruct.html
                        https://mp.weixin.qq.com/s/NOsXdrMrWwq4NTm180a6vw
3.redis缓存雪崩、击穿、穿透：
    a.缓存雪崩：
        缓存雪崩指的是缓存层支撑不住或宕掉后，大量请求（每秒万级）直接打向后端存储层，造成存储层级联宕机的情况。
        如何预防和解决：
            保证缓存层服务高可用性，比如使用redis主从或redis集群。这样一个redis实例宕掉后，还有其它实例支撑服务。
    b.缓存击穿：
        同一时间Key大面积失效，导致大量请求同时穿透缓存直达数据库，造成数据库瞬间压力过大甚至挂掉的情况。
        如何预防和解决：
            把每个Key的失效时间都加个随机值，可以保证Key不会在同一时间大面积失效，或者将Key设置为永久有效，有更新则更新。
        热点缓存key重建优化：
            针对“缓存+过期时间”的策略，可以利用互斥锁来解决。
    c.缓存穿透：
        缓存穿透是指查询一个根本不存在的数据，缓存层和存储层都不会命中，缓存穿透将导致不存在的数据每次请求都要到存储层去查询，失去了缓存保护后端存储的意义。
        造成缓存穿透的基本原因有两个：
            第一，自身业务代码或者数据出现问题。
            第二，一些恶意攻击、 爬虫等造成大量空命中。
        如何预防和解决：
            1.缓存空对象。
            2.布隆过滤器：
                对于恶意攻击，向服务器请求大量不存在的数据造成的缓存穿透，还可以用布隆过滤器先做一次过滤，对于不存在的数据布隆过滤器一般都能够过滤掉，不让请求再往后端发送。当布隆过滤器说某个值存在时，
                这个值可能不存在；当它说不存在时，那就肯定不存在。
                原理：
                    多个不一样的无偏hash函数（能够把元素的hash值算得比较均匀）和一个大型的位数组。
                    向布隆过滤器中添加key时，会使用多个无偏hash函数对key进行hash得到一个整数索引值然后对位数组长度进行取模得到一个位置，每个无偏hash函数都会算得一个不同的位置。
                    再把位数组的这几个位置都置为1就完成了add操作。向布隆过滤器查询key是否存在时，跟add一样，也会把hash的几个位置都算出来，看看位数组中这几个位置是否都为1，
                    只要有一个位为0，那么说明布隆过滤器中这个key不存在。如果都是1，这并不能说明这个key就一定存在，只是极有可能存在，因为这些位被置为1可能是因为其它的key存在所致。
                缺点：存在误判，删除困难。
                布隆过滤器适用于数据命中不高、数据相对固定、实时性低（通常是数据集较大）的应用场景，代码维护较为复杂，但是缓存空间占用很少。如：爬虫过滤、垃圾邮件过滤。
                BloomFilter使用：引入guava、redisson包。添加key的时候也要将key加到布隆过滤器中。
    d.缓存与数据库双写不一致：
        在大并发下，同时操作数据库与缓存会存在数据不一致性问题：
            1.双写不一致情况。
            2.读写不一致情况。
        解决方案：
            1.对于并发几率很小的数据(如个人维度的订单数据、用户数据等)，这种几乎不用考虑这个问题，很少会发生缓存不一致，可以给缓存数据加上过期时间，每隔一段时间触发读的主动更新即可。
            2.就算并发很高，如果业务上能容忍短时间的缓存数据不一致(如商品名称，商品分类菜单等)，缓存加上过期时间依然可以解决大部分业务对于缓存的要求。
            3.如果不能容忍缓存数据不一致，可以通过加读写锁保证并发读写或写写的时候按顺序排好队，读读的时候相当于无锁。
            4.也可以用阿里开源的canal通过监听数据库的binlog日志及时的去修改缓存，但是引入了新的中间件，增加了系统的复杂度。
        总结：
            以上我们针对的都是读多写少的情况加入缓存提高性能，如果写多读多的情况又不能容忍缓存数据不一致，那就没必要加缓存了，可以直接操作数据库。放入缓存的数据应该是对实时性、一致性要求不是很高的数据。
            切记不要为了用缓存，同时又要保证绝对的一致性做大量的过度设计和控制，增加系统复杂性！
4.redis持久化：
    a.RDB（snapshot）：
        在默认情况下，redis将内存数据库快照保存在名字为dump.rdb的二进制文件中。当“N秒内数据集至少有M个改动”这一条件被满足时，自动保存一次数据集，比如可以设置：
            # save 60 1000 //表示60秒内有至少有1000个键被改动时保存一次，关闭RDB只需要将所有的save保存策略注释掉即可
        也可以手动执行命令生成RDB快照，进入redis客户端执行命令save或bgsave可以生成dump.rdb文件，每次命令执行都会将所有redis内存快照到一个新的rdb文件里，并覆盖原有rdb快照文件。
        bgsave的写时复制(COW)机制以及与save的区别：
            redis借助操作系统提供的写时复制技术（Copy-On-Write, COW），在生成快照的同时，依然可以正常处理写命令。简单来说，bgsave子进程是由主线程fork生成的，可以共享主线程的所有内存数据。
            bgsave子进程运行后，开始读取主线程的内存数据，并把它们写入RDB文件。此时，如果主线程对这些数据也都是读操作，那么，主线程和bgsave子进程相互不影响。但是，如果主线程要修改一块数据，
            那么，这块数据就会被复制一份，生成该数据的副本。然后，bgsave子进程会把这个副本数据写入RDB文件，而在这个过程中，主线程仍然可以直接修改原来的数据。
            save与bgsave对比：
                命令                             save                bgsave
                IO类型                           同步                 异步
                是否阻塞redis其它命令              是                   否(在生成子进程执行调用fork函 数时会有短暂阻塞)
                复杂度                           O(n)                 O(n)
                优点                             不会消耗额外内存       不阻塞客户端命令
                缺点                             阻塞客户端命令         需要fork子进程，消耗内存
        配置自动生成rdb文件后台使用的是bgsave方式。
    b.AOF（append-only file）：
        RDB存在数据丢失的情况，如果redis因为某些原因而造成故障停机，那么服务器将丢失最近写入、且仍未保存到RDB中的那些数据。从1.1版本开始，redis增加了一种完全耐久的持久化方式-AOF持久化，
        将修改的每一条指令以追加的形式记录进文件appendonly.aof中(先写入os cache，每隔一段时间通过一个线程异步fsync到磁盘)。redis重新启动时，程序就可以通过重新执行AOF文件中的命令来达到重建数据集的目的。
        可以通过修改配置文件来打开AOF功能：
            # appendonly yes
        可以配置redis多久才将数据fsync到磁盘一次。有三个选项：
            appendfsync always：每次有新命令追加到AOF文件时就执行一次fsync，非常慢，也非常安全。
            appendfsync everysec：每秒fsync一次，足够快，并且在故障时只会丢失1秒钟的数据。
            appendfsync no：从不fsync，将数据交给操作系统来处理。更快，也更不安全的选择。
        推荐（并且也是默认）的措施为每秒fsync一次，这种fsync策略可以兼顾速度和安全性。
        AOF重写：
            AOF文件里可能有太多没用指令，所以AOF会定期根据内存的最新数据生成aof文件，AOF还可以手动重写，进入redis客户端执行命令bgrewriteaof重写AOF。
            注意，AOF重写redis会fork出一个子进程去做(与bgsave命令类似)，不会对redis正常命令处理有太多影响。
    RDB和AOF对比：
        命令               RDB           AOF
        启动优先级          低             高
        体积               小             大
        恢复速度            快             慢
        数据安全性          容易丢数据       根据策略决定
    生产环境可以都启用，redis启动时如果既有rdb文件又有aof文件则优先选择aof文件恢复数据，因为aof一般来说数据更全一点。
    c.redis4.0混合持久化：
        重启redis时，我们很少使用RDB来恢复内存状态，因为会丢失大量数据。我们通常使用AOF日志重放，但是重放AOF日志性能相对RDB来说要慢很多，这样在redis实例很大的情况下，启动需要花费很长的时间。
        redis4.0为了解决这个问题，带来了一个新的持久化选项——混合持久化。通过如下配置可以开启混合持久化(必须先开启aof)：
            # aof‐use‐rdb‐preamble yes
        如果开启了混合持久化，AOF在重写时，不再是单纯将内存数据转换为RESP命令写入AOF文件，而是将重写这一刻之前的内存做RDB快照处理，并且将RDB快照内容和增量的AOF修改内存数据的命令存在一起，都写入新的AOF文件，
        新的文件一开始不叫appendonly.aof，等到重写完新的AOF文件才会进行改名，覆盖原有的AOF文件，完成新旧两个AOF文件的替换。于是在redis重启的时候，可以先加载RDB的内容，
        然后再重放增量AOF日志就可以完全替代之前的AOF全量文件重放，因此重启效率大幅得到提升。
        混合持久化AOF文件结构如下：
            appendonly.aof
               RDB格式
               AOF格式
        混合持久化AOF文件结构如下redis数据备份策略：
        1.写crontab定时调度脚本，每小时都copy一份rdb或aof的备份到一个目录中去，仅仅保留最近48小时的备份。
        2.每天都保留一份当日的数据备份到一个目录中去，可以保留最近1个月的备份。
        3.每次copy备份的时候，都把太旧的备份给删了。
        4.每天晚上将当前机器上的备份复制一份到其他机器上，以防机器损坏。
5.redis集群高可用：
    a.redis主从复制架构：
        主（master），从（slave）
        主从复制原理：
            如果你为master配置了一个slave，不管这个slave是否是第一次连接上Master，它都会发送一个PSYNC命令给master请求复制数据。master收到PSYNC命令后，会在后台进行数据持久化通过bgsave生成最新的rdb快照文件，
            持久化期间，master会继续接收客户端的请求，它会把这些可能修改数据集的请求缓存在内存中。当持久化进行完毕以后，master会把这份rdb文件数据集发送给slave，slave会把接收到的rdb文件写进磁盘，再加载到内存中。
            然后，master再将之前缓存在内存中的命令发送给slave。当master与slave之间的连接由于某些原因而断开时，slave能够自动重连Master，如果master收到了多个slave并发连接请求，它只会进行一次持久化，
            而不是一个连接一次，然后再把这一份持久化的数据发送给多个并发连接的slave。
            数据部分复制（断点续传）：
                当master和slave断开重连后，一般都会对整份数据进行复制。但从redis2.8版本开始，redis改用可以支持部分数据复制的命令PSYNC去master同步数据，slave与master能够在网络连接断开重连后只进行部分数据复制(断点续传)。
                master会在其内存中创建一个复制数据用的缓存队列，缓存最近一段时间的数据，master和它所有的slave都维护了复制的数据下标offset和master的进程id，因此，当网络连接断开后，slave会请求master继续进行未完成的复制，
                从所记录的数据下标开始。如果master进程id变化了，或者从节点数据下标offset太旧，已经不在master的缓存队列里了，那么将会进行一次全量数据的复制。
                如果有很多从节点，为了缓解主从复制风暴(多个从节点同时复制主节点导致主节点压力过大)，可以让部分从节点与从节点(与主节点同步)同步数据。
    b.redis主从-哨兵架构：
        sentinel哨兵是特殊的redis服务，不提供读写服务，主要用来监控redis实例节点。哨兵架构下client端第一次从哨兵找出redis的主节点，后续就直接访问redis的主节点，不会每次都通过sentinel代理访问redis的主节点，
        当redis的主节点发生变化，哨兵会第一时间感知到，并且将新的redis主节点通知给client端(这里面redis的client端一般都实现了订阅功能，订阅sentinel发布的节点变动消息)。sentinel集群都启动完毕后，
        会将哨兵集群的元数据信息写入所有sentinel的配置文件里去(追加在文件的最下面)，我们查看下如下配置文件sentinel-26379.conf，如下所示：
            sentinel known‐replica mymaster 192.168.0.60 6380 #代表redis主节点的从节点信息
            sentinel known‐replica mymaster 192.168.0.60 6381 #代表redis主节点的从节点信息
            sentinel known‐sentinel mymaster 192.168.0.60 26380 52d0a5d70c1f90475b4fc03b6ce7c3c569 35760f #代表感知到的其它哨兵节点
            sentinel known‐sentinel mymaster 192.168.0.60 26381 e9f530d3882f8043f76ebb8e1686438ba8 bd5ca6 #代表感知到的其它哨兵节点
        当redis主节点如果挂了，哨兵集群会重新选举出新的redis主节点，同时会修改所有sentinel节点配置文件的集群元数据信息，比如6379的redis如果挂了，假设选举出的新主节点是6380，
        则sentinel文件里的集群元数据信息会变成如下所示：
            sentinel known‐replica mymaster 192.168.0.60 6379 #代表主节点的从节点信息
            sentinel known‐replica mymaster 192.168.0.60 6381 #代表主节点的从节点信息
            sentinel known‐sentinel mymaster 192.168.0.60 26380 52d0a5d70c1f90475b4fc03b6ce7c3c569 35760f #代表感知到的其它哨兵节点
            sentinel known‐sentinel mymaster 192.168.0.60 26381 e9f530d3882f8043f76ebb8e1686438ba8 bd5ca6 #代表感知到的其它哨兵节点
        同时还会修改sentinel文件里之前配置的mymaster对应的6379端口，改为6380：
            sentinel monitor mymaster 192.168.0.60 6380 2（quorum，quorum是一个数字，指明当有多少个sentinel认为一个master失效时(值一般为：sentinel总数/2 + 1)，master才算真正失效）
        当6379的redis实例再次启动时，哨兵集群根据集群元数据信息就可以将6379端口的redis节点作为从节点加入集群。
        哨兵组件的主要功能：
            集群监控：负责监控redis master和slave进程是否正常工作。
            消息通知：如果某个redis实例有故障，那么哨兵负责发送消息作为报警通知给管理员。
            故障转移：如果master node挂掉了，会自动转移到slave node上。
            配置中心：如果故障转移发生了，通知client客户端新的master地址。
        哨兵leader选举流程：
            当一个master服务器被某sentinel视为下线状态后，该sentinel会与其他sentinel协商选出sentinel的leader进行故障转移工作。每个发现master服务器进入下线的sentinel都可以要求其他sentinel选自己为sentinel的leader，
            选举是先到先得。同时每个sentinel每次选举都会自增配置纪元(选举周期)，每个纪元中只会选择一个sentinel的leader。如果所有超过一半的sentinel选举某sentinel作为leader。之后该sentinel进行故障转移操作，
            从存活的slave中选举出新的master，这个选举过程跟集群的master选举很类似。哨兵集群只有一个哨兵节点，redis的主从也能正常运行以及选举master，如果master挂了，那唯一的那个哨兵节点就是哨兵leader了，
            可以正常选举新master。不过为了高可用一般都推荐至少部署三个哨兵节点。为什么推荐奇数个哨兵节点原理跟集群奇数个master节点类似。
    c.redis集群（cluster）架构：
        在redis3.0以前的版本要实现集群一般是借助哨兵sentinel工具来监控master节点的状态，如果master节点异常，则会做主从切换，将某一台slave作为master，哨兵的配置略微复杂，并且性能和高可用性等各方面表现一般，
        特别是在主从切换的瞬间存在访问瞬断的情况，而且哨兵模式只有一个主节点对外提供服务，没法支持很高的并发，且单个主节点内存也不宜设置得过大，否则会导致持久化文件过大，影响数据恢复或主从同步的效率。

        redis集群是一个由多个主从节点群组成的分布式服务器群，它具有复制、高可用和分片特性。redis集群不需要sentinel哨兵也能完成节点移除和故障转移的功能。需要将每个节点设置成集群模式，这种集群模式没有中心节点，可水平扩展，
        据官方文档称可以线性扩展到上万个节点(官方推荐不超过1000个节点)。redis集群的性能和高可用性均优于之前版本的哨兵模式，且集群配置非常简单。
        1.redis集群搭建：
            redis集群需要至少三个master节点，并且要给每个master再搭建一个slave节点，总共6个redis节点，可以用三台机器部署6个redis实例，每台机器一主一从。
        2.redis集群原理：
            redis Cluster将所有数据划分为16384个slots(槽位)，每个节点负责其中一部分槽位。槽位的信息存储于每个节点中。当redis Cluster的客户端来连接集群时，它也会得到一份集群的槽位配置信息并将其缓存在客户端本地。
            这样当客户端要查找某个key时，可以直接定位到目标节点。同时因为槽位的信息可能会存在客户端与服务器不一致的情况，还需要纠正机制来实现槽位信息的校验调整。
            槽位定位算法：
                Cluster默认会对key值使用crc16算法进行hash得到一个整数值，然后用这个整数值对16384进行取模来得到具体槽位。HASH_SLOT = CRC16(key) mod 16384
            跳转重定位：
                当客户端向一个错误的节点发出了指令，该节点会发现指令的key所在的槽位并不归自己管理，这时它会向客户端发送一个特殊的跳转指令携带目标操作的节点地址，告诉客户端去连这个节点去获取数据。
                客户端收到指令后除了跳转到正确的节点上去操作，还会同步更新纠正本地的槽位映射表缓存，后续所有key将使用新的槽位映射表。
            redis集群节点间的通信机制：
                redis cluster节点间采取gossip协议进行通信
                    维护集群的元数据(集群节点信息，主从角色，节点数量，各节点共享的数据等)有两种方式：集中式和gossip。
                    1.集中式：
                        优点在于元数据的更新和读取，时效性非常好，一旦元数据出现变更立即就会更新到集中式的存储中，其他节点读取的时候立即就可以立即感知到；不足在于所有的元数据的更新压力全部集中在一个地方，
                        可能导致元数据的存储压力。很多中间件都会借助zookeeper集中式存储元数据。
                    2.gossip：
                        gossip协议包含多种消息，包括ping，pong，meet，fail等等。
                            meet：某个节点发送meet给新加入的节点，让新节点加入集群中，然后新节点就会开始与其他节点进行通信；
                            ping：每个节点都会频繁给其他节点发送ping，其中包含自己的状态还有自己维护的集群元数据，互相通过ping交换元数据(类似自己感知到的集群节点增加和移除，hash slot信息等)；
                            pong：对ping和meet消息的返回，包含自己的状态和其他信息，也可以用于信息广播和更新；
                            fail：某个节点判断另一个节点fail之后，就发送fail给其他节点，通知其他节点，指定的节点宕机了。
                        gossip协议的优点在于元数据的更新比较分散，不是集中在一个地方，更新请求会陆陆续续，打到所有节点上去更新，有一定的延时，降低了压力；缺点在于元数据更新有延时可能导致集群的一些操作会有一些滞后。
                        gossip通信的10000端口：
                            每个节点都有一个专门用于节点间gossip通信的端口，就是自己提供服务的端口号+10000，比如7001，那么用于节点间通信的就是17001端口。 每个节点每隔一段时间都会往另外几个节点发送ping消息，
                            同时其他几点接收到ping消息之后返回pong消息。
            网络抖动：
                机房网络往往并不总是稳定的，它们经常会发生各种各样的小问题。比如网络抖动就是非常常见的一种现象，突然之间部分连接变得不可访问，然后很快又恢复正常。为解决这种问题，
                redis Cluster提供了一种选项cluster-node-timeout，表示当某个节点持续timeout的时间失联时，才可以认定该节点出现故障，需要进行主从切换。如果没有这个选项，网络抖动会导致主从频繁切换(数据的重新复制)。
            redis集群选举原理：
                补充：判断节点宕机
                    在cluster-node-timeout内，某个节点一直没有返回pong，那么就被认为pfail，如果一个节点认为某个节点pfail了，那么会在gossip ping消息中，ping给其他节点，如果超过半数的节点都认为pfail了，
                    那么就会变成fail。
                当slave发现自己的master变为FAIL状态时，便尝试进行Failover，以期成为新的master。由于挂掉的master 可能会有多个slave，从而存在多个slave竞争成为master节点的过程， 其过程如下：
                    1.slave发现自己的master变为FAIL。
                    2.将自己记录的集群currentEpoch（集群的配置纪元）加1，并广播FAILOVER_AUTH_REQUEST信息，要求收到请求的master给自己投票。
                    3.master收到请求，判断请求者的合法性（是不是第一个给自己发送请求的slave并且自己是不是在处理槽位），如果合法并且自己并未给其他slave投过票，则发送FAILOVER_AUTH_ACK给这个slave，
                      master对每一个epoch（集群的配置纪元）只发送一次ack（即具有投票权的的master只能投票一次）。
                    4.尝试failover的slave收集master返回的FAILOVER_AUTH_ACK。
                    5.如果slave收到超过半数master的ack，就会变成新Master（这里解释了集群为什么至少需要三个主节点，如果只有两个，当其中一个挂了，只剩一个主节点是不能选举成功的）。
                    6.slave广播Pong消息通知其他集群节点。
                从节点并不是在主节点一进入FAIL状态就马上尝试发起选举，而是有一定延迟，一定的延迟确保我们等待FAIL状态在集群中传播，slave如果立即尝试选举，其它masters或许尚未意识到FAIL状态，可能会拒绝投票。
                延迟计算公式：
                    DELAY = 500ms + random(0 ~ 500ms) + SLAVE_RANK * 1000ms
                    SLAVE_RANK表示此slave已经从master复制数据的总量的rank。Rank越小代表已复制的数据越新。这种方式下，持有最新数据的slave将会首先发起选举（理论上）。
            集群脑裂数据丢失问题：
                脑裂问题：由于网络故障，造成集群节点之间（slave-master或master-master或slave-slave）出现数据不一致的情况。
                    哨兵模式下的脑裂：
                        当哨兵找不到主节点的时候，认为主节点宕机；需要选举备份节点，选举一个备份作为主节点。旧master上的客户端连接如果有未中断的，可以继续写入数据；新的master处理新的客户端写操作。两个主节点数据不一致。
                        当旧的master与哨兵恢复通讯，旧的master降级为slave。新的master将新写入的数据，同步到旧的master中，但是缺少旧的master中写入的数据。数据丢失。
                    集群模式下的脑裂：
                        集群中的多节点通讯出现问题，造成多个集群同时出现，多个主节点同时写数据，等网络恢复其中有些主节点会降为从节点，这时会有大量数据丢失。
                规避方法可以在redis配置里加上参数(这种方法不可能百分百避免数据丢失，参考集群leader选举机制)：
                    min‐replicas‐to‐write 1 //写数据成功最少同步的slave数量，这个数量可以模仿大于半数机制配置，比如集群总共三个节点可以配置1，加上leader就是2，超过了半数。
                    注意：这个配置在一定程度上会影响集群的可用性，比如slave要是少于1个，这个集群就算leader正常也不能提供服务了，需要具体场景权衡选择。
            集群是否完整才能对外提供服务：
                当redis.conf的配置cluster-require-full-coverage为no时，表示当负责一个插槽的主库下线且没有相应的从库进行故障恢复时，集群仍然可用，如果为yes则集群不可用。
            redis集群为什么至少需要三个master节点，并且推荐节点数为奇数？
                因为新master的选举需要大于半数的集群master节点同意才能选举成功，如果只有两个master节点，当其中一个挂了，是达不到选举新master的条件的。奇数个master节点可以在满足选举该条件的基础上节省一个节点，
                比如三个master节点和四个master节点的集群相比，大家如果都挂了一个master节点都能选举新master节点，如果都挂了两个master节点都没法选举新master节点了，所以奇数的master节点更多的是从节省机器资源角度出发说的。
            redis集群对批量操作命令的支持：
                对于类似mset，mget这样的多个key的原生批量操作命令，redis集群只支持所有key落在同一slot的情况，如果有多个key一定要用mset命令在redis集群上操作，则可以在key的前面加上{XX}，
                这样参数数据分片hash计算的只会是大括号里的值，这样能确保不同的key能落到同一slot里去，示例如下：
                    mset {user1}:1:name zhuge {user1}:1:age 18
                假设name和age计算的hash slot值不一样，但是这条命令在集群下执行，redis只会用大括号里的user1做hash slot计算，所以算出来的slot值肯定相同，最后都能落在同一slot。
6.redis过期键清除策略：
    1.惰性删除：当读/写一个已经过期的key时，删除掉这个key。
    2.主动删除：由于惰性删除策略无法保证冷数据被及时删掉，所以Redis会定期主动淘汰一批已过期的key，默认100ms就随机抽一些（全部扫描浪费性能）设置了过期时间的key，去检查是否过期，过期就删除。
    3.当前已用内存超过maxmemory限定时，触发主动清理策略（内存淘汰机制）。
        内存淘汰机制在Redis4.0之前一共实现了6种内存淘汰策略，在4.0之后，又增加了2种策略，总共8种：
            a) 针对设置了过期时间的key做处理：
                1.volatile-ttl：在筛选时，会针对设置了过期时间的键值对，根据过期时间的先后进行删除，越早过期的越先被删除。
                2.volatile-random：就像它的名称一样，在设置了过期时间的键值对中，进行随机删除。
                3.volatile-lru：会使用LRU算法筛选设置了过期时间的键值对删除。
                4.volatile-lfu：会使用LFU算法筛选设置了过期时间的键值对删除。
            b) 针对所有的key做处理：
                5.allkeys-random：从所有键值对中随机选择并删除数据。
                6.allkeys-lru：使用LRU算法在所有数据中进行筛选删除。
                7.allkeys-lfu：使用LFU算法在所有数据中进行筛选删除。
            c) 不处理：
                8.noeviction：不会剔除任何数据，拒绝所有写入操作并返回客户端错误信息"(error) OOM command not allowed when used memory"，此时Redis只响应读操作。
        LRU算法（Least Recently Used，最近最少使用）淘汰很久没被访问过的数据，以最近一次访问时间作为参考。
        LFU算法（Least Frequently Used，最不经常使用）淘汰最近一段时间被访问次数最少的数据，以次数作为参考。
        当存在热点数据时，LRU的效率很好，但偶发性的、周期性的批量操作会导致LRU命中率急剧下降，缓存污染情况比较严重。这时使用LFU可能更好点。
        根据自身业务类型，配置好maxmemory-policy(默认是noeviction)，推荐使用volatile-lru。如果不设置最大内存，当Redis内存超出物理内存限制时，内存的数据会开始和磁盘产生频繁的交换 (swap)，会让Redis的性能急剧下降。
        当Redis运行在主从模式时，只有主结点才会执行过期删除策略，然后把删除操作”del key”同步到从结点删除数据。
7.redis分布式锁：
    1.实现原理：
        借助setnx（SET if Not Exists）命令，如果不存在，则SET值，成功返回int 1，否则返回int 0，除此之外还要设置一个锁过期时间，一般以秒为单位，释放锁则删除key。
        获取锁的过程：
            key设为任意字符串，value设为当前时间+锁过期时间，再设置一个获取锁的超时时间以及一个极短的步长时间（自旋时间），先尝试setnx，如果成功则获取锁成功，否则获取value判断锁是否过期，如果已过期，则尝试setex更新value（当前时间+锁过期时间并转为时间戳）
            同时比较返回的旧值是否与之前查询的旧值相等，如果相等则获取锁成功，否则将超时时间减去步长时间，并让当前线程sleep步长时间。然后循环往复直至获取到锁或者超时结束。释放锁则删除key。
    2.对比zookeeper实现：
        zookeeper分布式锁主要借助已设置的节点不能重复设置这一特点实现，释放锁则删除节点。
        获取锁的过程：与redis获取锁的过程相似，其中线程设置节点失败则sleep一定的时间，设置的节点为临时节点，相当于redis分布式锁中过期时间的作用，释放锁则删除节点。
8.redis与memCache的区别：
    1.数据类型：
        redis数据类型丰富，支持set、list等类型。
        memCache支持简单数据类型，需要客户端自己处理复杂对象。
    2.持久性：
        redis支持数据落地持久化存储。
        memCache不支持数据持久存储。
    3.分布式存储：
        redis支持master-slave复制模式。
        memCache可以使用一致性hash做分布式。
    4.value大小不同：
        memCache是一个内存缓存，key的长度小于250字节，单个item存储要小于1M，不适合虚拟机使用。
    5.数据一致性不同：
        redis使用的是单线程模型，保证了数据按顺序提交。
        memCache需要使用cas保证数据一致性。
    6.cpu利用：
        redis单线程模型只能使用一个cpu，可以开启多个redis进程。
        memCache可以使用多个cpu。
